{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142caebe-ccdf-44e4-990c-6c14f0f9b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 17:19:19.220873: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 17:19:19.437577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-16 17:19:19.437613: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-16 17:19:20.518000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-16 17:19:20.518102: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-16 17:19:20.518114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils import load_encoder_hparams_and_params\n",
    "encoder, hparams, params = load_encoder_hparams_and_params(\"124M\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7a2b34-fdee-40d2-96b8-0f5e6b5abe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[439, 10281, 5806, 1451, 274]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = encoder.encode(\"all heroes wear capes\")\n",
    " \n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681152f0-ae34-4d17-b5ff-cabfc69a8491",
   "metadata": {},
   "source": [
    "## Import weights one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d8b9c92-1d27-4601-ade5-1523abad38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "b = np.load('saved_weights/model_ln_f_b.npy', allow_pickle=True)\n",
    "g = np.load('saved_weights/model_ln_f_g.npy', allow_pickle=True)\n",
    " \n",
    "c_attn_b = np.load('saved_weights/model_h0_attn_c_attn_b.npy', allow_pickle=True)\n",
    "c_attn_w = np.load('saved_weights/model_h0_attn_c_attn_w.npy', allow_pickle=True)\n",
    " \n",
    "\n",
    "c_proj_b = np.load('saved_weights/model_h0_attn_c_proj_b.npy', allow_pickle=True) \n",
    "c_proj_w = np.load('saved_weights/model_h0_attn_c_proj_w.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ee2db-9034-4f5a-a917-9f9b21dcaa4a",
   "metadata": {},
   "source": [
    "## Helper funciton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e346f764-eeed-48f5-b0f8-ca42e8df6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, mask):\n",
    "    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99faf5eb-2d12-4557-bfc9-5922c5f79eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, w, b):  # [m, in], [in, out], [out] -> [m, out]\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238b54eb-944b-49be-aeb7-3a7ae97f1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mha(x, c_attn, c_proj, n_head=1):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "     x = linear(x, c_attn_w , c_attn_b)  # [n_seq, n_embd] -> [n_seq, 3*n_embd]\n",
    "\n",
    "     qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -> [3, n_seq, n_embd]\n",
    "\n",
    "     qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\n",
    "\n",
    "     causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]\n",
    "\n",
    "     out_heads = [attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)]  # [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\n",
    "\n",
    "     x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\n",
    "\n",
    "     x = linear(x, c_proj_w,c_proj_b )  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "\n",
    "     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9219f79a-b70d-4db3-9b0f-37d8c45210c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(x, mlp, attn, ln_1, ln_2, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "     \n",
    "    x =  mha(x, **attn, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "\n",
    "   \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651c76ff-7b6b-47a7-aaa5-1a8e39169a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):\n",
    "    x = wte[inputs] + wpe[range(len(inputs))]\n",
    "    for block in blocks[:1]:\n",
    "      x = transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6f3152-3f12-4413-b5cd-7ca5a4014433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x, g, b, eps: float = 1e-5):\n",
    "    print(\"Layer Norm Input Shapes:\")\n",
    "    print(f\"x: {x}\")\n",
    "    print(f\"x shape: {x.shape}\")\n",
    "    print(f\"g shape: {g.shape}\")\n",
    "    print(f\"b shape: {b.shape}\")\n",
    "    \n",
    "    mean = np.mean(x, axis=-1, keepdims=True)\n",
    "    print(f\"mean: {mean}\")\n",
    "    variance = np.var(x, axis=-1, keepdims=True)\n",
    "    print(f\"variance: {variance}\")\n",
    "    \n",
    "    x_normalized = (x - mean) / np.sqrt(variance + eps)\n",
    "    print(f\"x_normalized: {x_normalized}\")\n",
    "    \n",
    "    result = g * x_normalized + b\n",
    "    print(f\"result: {result}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273809e8-2147-46a2-a400-80b7e85da9cd",
   "metadata": {},
   "source": [
    "## Sequential implementation of GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d126ab4b-75d3-4875-bf35-c88e0b5c37b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mgpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# model forward pass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m, in \u001b[0;36mgpt2\u001b[0;34m(inputs, wte, wpe, blocks, ln_f, n_head)\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m wte[inputs] \u001b[38;5;241m+\u001b[39m wpe[\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m blocks[:\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n_seq, n_embd] -> [n_seq, n_embd]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m, in \u001b[0;36mtransformer_block\u001b[0;34m(x, mlp, attn, ln_1, ln_2, n_head)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformer_block\u001b[39m(x, mlp, attn, ln_1, ln_2, n_head):  \u001b[38;5;66;03m# [n_seq, n_embd] -> [n_seq, n_embd]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     x \u001b[38;5;241m=\u001b[39m  \u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n_seq, n_embd] -> [n_seq, n_embd]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mmha\u001b[0;34m(x, c_attn, c_proj, n_head)\u001b[0m\n\u001b[1;32m      6\u001b[0m qkv_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msplit(x, n_head, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), qkv))  \u001b[38;5;66;03m# [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtri(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e10\u001b[39m  \u001b[38;5;66;03m# [n_seq, n_seq]\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m out_heads \u001b[38;5;241m=\u001b[39m [attention(q, k, v, causal_mask) \u001b[38;5;28;01mfor\u001b[39;00m q, k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mqkv_heads)]  \u001b[38;5;66;03m# [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(out_heads)  \u001b[38;5;66;03m# [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m linear(x, c_proj_w,c_proj_b )  \u001b[38;5;66;03m# [n_seq, n_embd] -> [n_seq, n_embd]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m qkv_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msplit(x, n_head, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), qkv))  \u001b[38;5;66;03m# [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtri(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e10\u001b[39m  \u001b[38;5;66;03m# [n_seq, n_seq]\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m out_heads \u001b[38;5;241m=\u001b[39m [\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m q, k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mqkv_heads)]  \u001b[38;5;66;03m# [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(out_heads)  \u001b[38;5;66;03m# [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m linear(x, c_proj_w,c_proj_b )  \u001b[38;5;66;03m# [n_seq, n_embd] -> [n_seq, n_embd]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mattention\u001b[0;34m(q, k, v, mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattention\u001b[39m(q, k, v, mask):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoftmax\u001b[49m(q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m mask) \u001b[38;5;241m@\u001b[39m v\n",
      "\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"
     ]
    }
   ],
   "source": [
    "logits = gpt2(inputs, **params, n_head=1)  # model forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a8c51-5519-428e-8fed-7148bd3c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4fb297-d097-4b91-ae17-85485b4659e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Norm Input Shapes:\n",
      "x: [[ 0.12479967 -0.18312944  0.12330008 ... -0.23028293  0.07496844\n",
      "   0.00799115]\n",
      " [-0.07021496 -0.13564175 -0.01681434 ... -0.00921412 -0.06527534\n",
      "  -0.11999762]\n",
      " [-0.01704012 -0.25538594  0.16463962 ... -0.04039633 -0.02198055\n",
      "   0.02862293]\n",
      " [ 0.11016754  0.00768144  0.16934796 ... -0.16861892  0.14384717\n",
      "  -0.0459881 ]\n",
      " [-0.19569312  0.02489605  0.33249626 ...  0.05738477 -0.05327084\n",
      "   0.03864006]]\n",
      "x shape: (5, 768)\n",
      "g shape: (768,)\n",
      "b shape: (768,)\n",
      "mean: [[-0.00529166]\n",
      " [-0.00109631]\n",
      " [-0.00258127]\n",
      " [-0.00253499]\n",
      " [-0.00225833]]\n",
      "variance: [[0.14235575]\n",
      " [0.05211692]\n",
      " [0.04362927]\n",
      " [0.03986736]\n",
      " [0.04037109]]\n",
      "x_normalized: [[ 0.3447828  -0.4713259   0.3408084  ... -0.59629744  0.21271442\n",
      "   0.03520361]\n",
      " [-0.30273613 -0.58930206 -0.06884418 ... -0.0355556  -0.28110084\n",
      "  -0.5207816 ]\n",
      " [-0.06921417 -1.2101698   0.8004824  ... -0.18101977 -0.09286391\n",
      "   0.14937373]\n",
      " [ 0.5643785   0.05116062  0.86073524 ... -0.8316957   0.7330354\n",
      "  -0.21759939]\n",
      " [-0.9625994   0.1351297   1.6658562  ...  0.296805   -0.25385615\n",
      "   0.20352474]]\n",
      "result: [[ 0.48277646 -0.61152154  0.5757946  ... -0.66803676  0.20801392\n",
      "   0.07694179]\n",
      " [-0.42185956 -0.7737332  -0.19720215 ... -0.04932585 -0.33417445\n",
      "  -0.5941485 ]\n",
      " [-0.09561059 -1.6273971   1.4431796  ... -0.20982799 -0.12749822\n",
      "   0.21474844]\n",
      " [ 0.7895693   0.10687283  1.556874   ... -0.92777026  0.7793045\n",
      "  -0.22819878]\n",
      " [-1.3437415   0.22232637  3.0761025  ...  0.31739396 -0.30426094\n",
      "   0.2801103 ]]\n"
     ]
    }
   ],
   "source": [
    "logits1 = layer_norm(logits,g,b)  # [n_seq, n_embd] -> [n_seq, n_embd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb42cb60-f893-4055-a476-75714aabe860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fb7b4-d97d-4fe0-ba7f-5355b5575f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e3cdf-6583-45e0-aa8a-b9ae28601a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34e38e-3703-43a6-9976-4c67d0e94947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af48f2b8-49d0-46e2-bdc7-8ff52328ffa2",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a95a1-37e7-4615-81b1-26f872eeccbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8313df6-2d63-48a5-b901-786ced2e2297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35121146-db3f-4773-9f2e-66fc2aff5da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
